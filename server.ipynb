{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPY/Z0GI0Cgra0jStNN0kzu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Od18C1kJY7OP"},"outputs":[],"source":["# ==============================================================================\n","# 1. GEREKLİ KURULUMLAR\n","# ==============================================================================\n","print(\"Eski önbellek (cache) temizleniyor...\")\n","!rm -rf /root/.cache/huggingface/\n","\n","print(\"Gerekli kütüphaneler kuruluyor...\")\n","!pip install flask pyngrok transformers accelerate bitsandbytes huggingface_hub torch --quiet\n","!apt-get install -y tshark\n","\n","# ==============================================================================\n","# 2. GEREKLİ MODÜLLER VE GİRİŞ İŞLEMLERİ\n","# ==============================================================================\n","from flask import Flask, request, jsonify\n","from pyngrok import ngrok\n","from google.colab import userdata\n","from huggingface_hub import login\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","import subprocess\n","import os\n","import re\n","import threading\n","import time\n","import json # JSON çıktısını parse etmek için\n","\n","# Token'ları al (HF_TOKEN, Llama-3 erişimi için zorunludur)\n","try:\n","    hf_token = userdata.get('HF_TOKEN')\n","    if hf_token:\n","        login(token=hf_token)\n","        print(\"Hugging Face'e başarılı bir şekilde giriş yapıldı.\")\n","    else:\n","        print(\"Hata: HF_TOKEN bulunamadı. Llama-3 erişimi için bu zorunludur.\")\n","\n","    ngrok_token = userdata.get('NGROK_AUTHTOKEN')\n","    if ngrok_token:\n","        ngrok.set_auth_token(ngrok_token)\n","        print(\"Ngrok kimlik doğrulaması yapıldı.\")\n","    else:\n","        print(\"UYARI: NGROK_AUTHTOKEN bulunamadı.\")\n","\n","except Exception as e:\n","    print(f\"Token hatası: {e}\")\n","\n","# ==============================================================================\n","# 3. MODEL YÜKLEME VE GENERATE FONKSİYONU (İstenen Pcap Modeli)\n","# ==============================================================================\n","print(\"\\nModel ve Tokenizer yükleniyor... (choihyuunmin/LLaMa-PcapLog)\")\n","model = None\n","tokenizer = None\n","try:\n","    # Model ID'si, sizin istediğiniz ve erişim izni aldığınız model\n","    model_id = \"choihyuunmin/LLaMa-PcapLog\"\n","\n","    tokenizer = AutoTokenizer.from_pretrained(model_id)\n","\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_id,\n","        torch_dtype=\"auto\", # Llama modelleri için 'auto' en iyisidir\n","        device_map=\"auto\"   # Modeli otomatik olarak GPU'ya yükler\n","    )\n","    print(\"Model (choihyuunmin/LLaMa-PcapLog) başarıyla yüklendi.\")\n","\n","except Exception as e:\n","    print(f\"HATA: Model yüklenemedi: {e}\")\n","    print(\"Lütfen Meta Llama-3 için erişim izninizin (gated repo) onaylandığından emin olun.\")\n","\n","# Generate fonksiyonu Llama modelleri için optimize edildi\n","def generate(prompt, **kwargs):\n","    \"\"\"LLM'den bir yanıt üretir.\"\"\"\n","    if not model or not tokenizer: return \"Model veya Tokenizer yüklenemedi.\"\n","\n","    model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n","\n","    # max_new_tokens=512: JSON cevabı için yeterli alan bırakır\n","    generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512, **kwargs)\n","\n","    # Sadece üretilen yeni token'ları ayıkla\n","    generated_ids = [\n","        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n","    ]\n","\n","    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","    return response.strip()\n","\n","# ==============================================================================\n","# 4. FLASK SUNUCUSU VE API ENDPOINT'İ (Cerrahi Engelleme Mantığı)\n","# ==============================================================================\n","app = Flask(__name__)\n","\n","@app.route('/analyze', methods=['POST'])\n","def analyze_pcap():\n","    if 'pcap_file' not in request.files:\n","        return jsonify({\"error\": \"İstekte 'pcap_file' adında bir dosya bulunamadı.\", \"blocked_ips\": []}), 400\n","    file = request.files['pcap_file']\n","    if not file:\n","        return jsonify({\"error\": \"Dosya seçilmedi.\", \"blocked_ips\": []}), 400\n","\n","    filepath = os.path.join(\"uploads\", f\"batch_{int(time.time())}.pcap\")\n","    os.makedirs(\"uploads\", exist_ok=True)\n","    file.save(filepath)\n","\n","    try:\n","        # --- 1. Adım: TShark ile .pcap dosyasını analiz et ---\n","        try:\n","            print(f\"Gelen dosya {filepath} TShark ile analiz ediliyor...\")\n","            command = [\"tshark\", \"-r\", filepath, \"-q\", \"-z\", \"io,phs\", \"-z\", \"conv,tcp\"]\n","            process = subprocess.run(command, capture_output=True, text=True, check=True)\n","            pcap_summary = process.stdout\n","            print(\"TShark analizi tamamlandı.\")\n","        except subprocess.CalledProcessError as e:\n","            return jsonify({\"error\": f\"TShark analiz hatası: {e.stderr}\", \"blocked_ips\": []}), 500\n","        except FileNotFoundError:\n","            return jsonify({\"error\": \"Sunucuda 'tshark' komutu bulunamadı.\", \"blocked_ips\": []}), 500\n","\n","        # --- 2. Adım: LLM için YENİ Prompt Hazırla ---\n","        # İstemcinin \"sadece riskli IP'yi engelle\" talebine uymak için,\n","        # Pcap modeline SKOR sormak yerine, JSON listesi istiyoruz.\n","        print(\"LLM için JSON tabanlı prompt hazırlanıyor...\")\n","        prompt = f\"\"\"\n","You are a senior cybersecurity analyst AI specialized in pcap analysis (LLaMa-PcapLog). Your task is to analyze the following TShark network traffic summary and identify malicious source IP addresses.\n","\n","**TASK:**\n","1.  Analyze the summary. Look for signs of port scanning, C2 communication, or other anomalies.\n","2.  Respond with a JSON object.\n","3.  The JSON object *must* contain a key named \"blocked_ips\" which is a list of strings (source IP addresses) that you deem malicious.\n","4.  The JSON object *must* also contain a \"reason\" key explaining your decision.\n","\n","**EXAMPLE RESPONSES:**\n","- If a port scan is detected from '1.2.3.4':\n","{{\"blocked_ips\": [\"1.2.3.4\"], \"reason\": \"Port scan detected from 1.2.3.4, targeting multiple ports.\"}}\n","- If traffic is normal:\n","{{\"blocked_ips\": [], \"reason\": \"Traffic appears normal. No malicious activity detected.\"}}\n","\n","**Begin Analysis:**\n","\n","--- NETWORK TRAFFIC SUMMARY ---\n","{pcap_summary}\n","--- ANALYSIS RESULT (JSON Only) ---\n","\"\"\"\n","\n","        model_output = generate(prompt)\n","        print(f\"LLM Ham Çıktısı: {model_output}\")\n","\n","        # --- 3. Adım: LLM Çıktısını (JSON) Parse Et ve Döndür ---\n","        try:\n","            # Modelin çıktısından sadece JSON kısmını ayıkla\n","            json_match = re.search(r'\\{.*\\}', model_output, re.DOTALL)\n","\n","            if json_match:\n","                response_json_str = json_match.group(0)\n","                response_data = json.loads(response_json_str)\n","\n","                # İstemcinin beklediği anahtarları doğrula\n","                if \"blocked_ips\" not in response_data:\n","                    response_data[\"blocked_ips\"] = []\n","                if \"reason\" not in response_data:\n","                    response_data[\"reason\"] = \"Model JSON döndürdü ancak 'reason' anahtarı eksik.\"\n","\n","                print(f\"İstemciye gönderiliyor: {response_data}\")\n","                return jsonify(response_data)\n","\n","            else:\n","                print(\"Hata: Model çıktısında JSON bulunamadı.\")\n","                return jsonify({\"error\": \"Model çıktısında JSON bulunamadı.\", \"details\": model_output, \"blocked_ips\": []}), 500\n","\n","        except json.JSONDecodeError:\n","            print(\"Hata: Model geçerli bir JSON döndürmedi.\")\n","            return jsonify({\"error\": \"Model geçersiz JSON döndürdü.\", \"details\": model_output, \"blocked_ips\": []}), 500\n","\n","    except Exception as e:\n","        print(f\"API endpoint'inde beklenmedik hata: {e}\")\n","        return jsonify({\"error\": f\"Sunucu içi hata: {str(e)}\", \"blocked_ips\": []}), 500\n","\n","    finally:\n","        # Yüklenen .pcap dosyası her durumda silinir.\n","        if os.path.exists(filepath):\n","            os.remove(filepath)\n","            print(f\"Geçici dosya {filepath} silindi.\")\n","\n","# ==============================================================================\n","# 5. SUNUCUYU BAŞLATMA VE NGROK TÜNELİ OLUŞTURMA\n","# ==============================================================================\n","def run_app():\n","    app.run(host='0.0.0.0', port=5001) # Port 5001 kullanılıyor\n","\n","if model: # Model başarıyla yüklendiyse sunucuyu başlat\n","    flask_thread = threading.Thread(target=run_app)\n","    flask_thread.daemon = True\n","    flask_thread.start()\n","\n","    public_url = ngrok.connect(5001)\n","    print(\"\\n================================================================================\")\n","    print(\"SUNUCU HAZIR! (LLaMa-PcapLog Modeli ve Cerrahi Engelleme Aktif)\")\n","    print(f\"Raspberry Pi istemcisinde LLM_API_URL olarak bu adresi kullanın:\")\n","    print(f\"{public_url}/analyze\")\n","    print(\"================================================================================\")\n","else:\n","    print(\"\\nModel yüklenemediği için sunucu başlatılmadı.\")\n","\n","try:\n","    while True: time.sleep(3600)\n","except KeyboardInterrupt:\n","    ngrok.kill()\n","    print(\"Sunucu ve ngrok tüneli kapatıldı.\")"]}]}